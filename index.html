<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

<link rel="stylesheet" href="./Yu-Jie Zhang @ files/jemdoc.css" type="text/css">
<title>Yu-Jie Zhang</title>
</head>
<body data-gr-c-s-loaded="true" data-new-gr-c-s-check-loaded="14.1063.0" data-gr-ext-installed="">
<div id="layout-content">
<div id="toptitle">
<h1><span style="padding-left:10px;"></span><font size="+3">Yu-Jie Zhang @ RIKEN AIP</font> </h1>
</div>
<table class="imgtable"><tbody><tr>
<td><span style="padding-left:10px;"></span></td>
<td align="left" valign="top"><p>
<font style = "font-size: 1.08em;">Postdoc Researcher</a></font><br>
<font style = "font-size: 1.08em;"><a href="https://www.riken.jp/en/research/labs/aip/generic_tech/imperfect_inf_learn/index.html">Imperfect Information Learning Team</a></font><br>
<font style = "font-size: 1.08em;"><a href="https://www.riken.jp/en/research/labs/aip/">RIKEN Center for Advanced Intelligence Project</a></font> <br>
<font style = "font-size: 1.08em;"><b>Email</b>: yu-jie.zhang [at] riken.jp</font><br>
</p>
[<a href="./resume/twopage/CV_twopage.pdf">CV</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&user=ZDHyUSQAAAAJ">Google Scholar</a>, <a href="https://github.com/yjzzzzz">Github</a>]
</td>
<td><span style="padding-left:130px;"></span></td>
<td valign="top"><a href="./Yu-Jie Zhang @ files/zhangyj_photo1.jpg"><img src="./Yu-Jie Zhang @ files/zhangyj_photo1.jpg" alt="zhangyj_photo1.jpg" width="105 px" height="140 px"></a>&nbsp;</td>
</tr></tbody></table>




<h2>About Me</h2>
I am a postdoctoral researcher in the <a href="https://www.riken.jp/en/research/labs/aip/generic_tech/imperfect_inf_learn/index.html">Imperfect Information Learning Team</a> at <a href="https://www.riken.jp/en/research/labs/aip/">RIKEN AIP</a>. I earned my Ph.D. from <a href="https://www.u-tokyo.ac.jp/en/">the University of Tokyo</a> under the supervision of <a href="https://www.ms.k.u-tokyo.ac.jp/sugi/">Prof. Masashi Sugiyama</a>. Previously, I completed my M.Sc. with the LAMDA Group at <a href="http://www.nju.edu.cn/" target="_blank">Nanjing University</a>, under the supervision of <a href="https://cs.nju.edu.cn/zhouzh/index.htm">Prof. Zhi-Hua Zhou</a>.
<br>

<h2>Research Interests</h2>
<p>My research interests include Machine Learning and Data Mining. Currently, I am interested in 
</p>
<ul>
	<li style = "margin: 0px 0">Online Learning and Sequential Decision Making</li>
	<li style = "margin: 3px 0">Machine Learning in Non-stationary Environments</li>
</ul><br>

<!-- <div class="section" id="Preprints">
<h2>Preprints</h2>
<ul>

</ul> -->


<div class="section" id="Conference">
<h2>Conference Papers</h2>
<ul>
<li>
	Non-stationary Online Learning for Curved Losses: Improved Dynamic Regret via Mixability. [PDF forthcoming]
	<br>
	<u>Yu-Jie Zhang</u>, Peng Zhao, and Masashi Sugiyama.
	<br>
	In: Proceedings of the 42nd International Conference on Machine Learning <b>(ICML 2025)</b>, Vancouver, Canada, 2025. Page: to appear.
	<br><br>
</li>

<li>
Heavy-Tailed Linear Bandits: Huber Regression with One-Pass Update. [<a href="#">PDF</a>, <a href="https://arxiv.org/abs/2503.00419">arXiv</a>, bibtex]
<br>
Jing Wang, <u>Yu-Jie Zhang</u>, Peng Zhao, and Zhi-Hua Zhou.
<br>
In: Proceedings of the 42nd International Conference on Machine Learning <b>(ICML 2025)</b>, Vancouver, Canada, 2025. Page: to appear.
<br><br>
</li>

<li> 
Provably Efficient Reinforcement Learning with Multinomial Logit Function Approximation. [<a href="https://arxiv.org/abs/2405.17061">arXiv</a>]
<br>
Long-Fei Li, <u>Yu-Jie Zhang</u>, Peng Zhao, and Zhi-Hua Zhou.
<br>
In: Advances in Neural Information Processing Systems 37 <b>(NeurIPS 2024)</b>, Vancouver, Canada, 2023. Page: 58539-58573. 
<br><br>
</li>
<li>
Efficient Non-stationary Online Learning by Wavelets with Applications to Online Distribution Shift Adaptation. [<a href="https://openreview.net/pdf?id=KNedb3bQ4h">PDF</a>, <a href="./Yu-Jie Zhang @ files/bibtex/Efficient_ODS.html">bibtex</a>]
<br>
Yu-Yang Qian, Peng Zhao, <u>Yu-Jie Zhang</u>, Masashi Sugiyama, Zhi-Hua Zhou.
<br>
In: Proceedings of the 41st International Conference on Machine Learning <b>(ICML 2024)</b>, Vienna, Austria, 2024. Page: 41383-41415.
<br><br>
</li>
<li>
Learning with Complementary Labels Revisited: The Selected-Completely-at-Random Setting Is More Practical.  [<a href="https://openreview.net/pdf?id=ykZYLBcA9g">PDF</a>, <a href="./Yu-Jie Zhang @ files/bibtex/NUCL.html">bibtex</a>]
<br>
Wei Wang, Takashi Ishida, <u>Yu-Jie Zhang</u>, Gang Niu, Masashi Sugiyama.
<br>
In: Proceedings of the 41st International Conference on Machine Learning <b>(ICML 2024)</b>, Vienna, Austria. Page: 50683-50710.
<br><br>
</li>	
<li>
Adapting to Continuous Covariate Shift via Online Density Ratio Estimation. [<a href="./Yu-Jie Zhang @ files/paper/CovShift.pdf">PDF</a>, <a href="https://arxiv.org/abs/2302.02552">arXiv</a>, <a href="./Yu-Jie Zhang @ files/bibtex/CovShift.html">bibtex</a>]<br>
<u>Yu-Jie Zhang</u>, Zhen-Yu Zhang, Peng Zhao, and Masashi Sugiyama. <br>
In: Advances in Neural Information Processing Systems 36 <b>(NeurIPS 2023)</b>, New Orleans, Louisiana, 2023. Page: 29074-29113. 	
<br><br>
</li>	
<li>
Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost. [<a href="./Yu-Jie Zhang @ files/paper/MLogB.pdf">PDF</a>, <a href="./Yu-Jie Zhang @ files/bibtex/MLogB.html">bibtex</a>] (Spotlight)<br>
<u>Yu-Jie Zhang</u> and Masashi Sugiyama. <br>
In: Advances in Neural Information Processing Systems 36 <b>(NeurIPS 2023)</b>, New Orleans, Louisiana, 2023. Page: 29741-29782. 	
<br><br>
</li>	
<li>
Imitation Learning from Vague Feedback. [<a href="./Yu-Jie Zhang @ files/paper/VPIL.pdf">PDF</a>, <a href="./Yu-Jie Zhang @ files/bibtex/VPIL.html">bibtex</a>] <br>
Xin-Qiang Cai, <u>Yu-Jie Zhang</u>, Chao-Kai Chiang and Masashi Sugiyama. <br>
In: Advances in Neural Information Processing Systems 36 <b>(NeurIPS 2023)</b>, New Orleans, Louisiana, 2023. Page: 48275-48292. 	
<br><br>
</li>		
<li>
Adapting to Online Label Shift with Provable Guarantees. [<a href="./Yu-Jie Zhang @ files/paper/OLaS.pdf">PDF</a>, <a href="https://arxiv.org/abs/2207.02121">arXiv</a>, <a href = "http://www.lamda.nju.edu.cn/code_ATLAS.ashx" >code</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2022-NeurIPS-OLaS.html">bibtex</a>] 
<br>
Yong Bai*, <u>Yu-Jie Zhang</u>*, Peng Zhao, Masashi Sugiyama, and Zhi-Hua Zhou. (* indicates equal contribution) <br>
In: Advances in Neural Information Processing Systems 35 <b>(NeurIPS 2022)</b>, New Orleans, Louisiana, 2022. Page: 29960-29974.
<br><br>
</li>		
<li>
Adaptive Learning for Weakly Labeled Streams. [<a href="https://www.lamda.nju.edu.cn/zhangzy/KDD'22_AdaStreams.pdf">PDF</a>, <a href="https://www.lamda.nju.edu.cn/code_AdaStreams.ashx">code</a>, <a href="https://www.lamda.nju.edu.cn/zhangzy/bib/2022_KDD_AdaStreams.html">bibtex</a>] <br>
Zhen-Yu Zhang, Yu-Yang Qian, <u>Yu-Jie Zhang</u>, Yuan Jiang, Zhi-Hua Zhou.<br>
In: Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining <b>(KDD 2022)</b>, Washington, DC, 2022. 
<br><br>
</li>	
<li>
Towards Enabling Learnware to Handle Unseen Jobs. [<a href="http://129.211.169.156/publication/aaai21_unseenJob.pdf">PDF</a>,  <a href="http://www.lamda.nju.edu.cn/code_RKME_unseen.ashx">code</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2021-AAAI-UnseenJob.html">bibtex</a>]<br>
<u>Yu-Jie Zhang</u>, Yu-Hu Yan, Peng Zhao and Zhi-Hua Zhou. <br>
In: Proceedings of the 35th AAAI Conference on Artificial Intelligence <b>(AAAI 2021)</b>, online, 2021. Page: 10964-10972.
<br><br>
</li>
<li>
Exploratory Machine Learning with Unknown Unknowns.[<a href="https://www.lamda.nju.edu.cn/zhaop/publication/AAAI&#39;21-ExML.pdf">PDF</a>, <a href="http://www.lamda.nju.edu.cn/code_ExML.ashx">code</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2021-AAAI-ExML.html">bibtex</a>] <br> 
Peng Zhao, <u>Yu-Jie Zhang</u> and Zhi-Hua Zhou. <br>
In: Proceedings of the 35th AAAI Conference on Artificial Intelligence <b>(AAAI 2021)</b>, online, 2021. Page: 10999-11006. 
<br><br> 
</li>
<li>
An Unbiased Risk Estimator for Learning with Augmented Classes.[<a href="https://www.lamda.nju.edu.cn/zhaop/publication/NeurIPS&#39;20-Eulac.pdf">PDF</a>,  <a href="https://arxiv.org/abs/1910.09388">arXiv</a>, <a href="http://www.lamda.nju.edu.cn/code_Eulac.ashx">code</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2020-NeurIPS-Eulac.html">bibtex</a>]<br>
<u>Yu-Jie Zhang</u>, Peng Zhao, Lanjihong Ma and Zhi-Hua Zhou. <br>
 In: Advances in Neural Information Processing Systems 33 <b>(NeurIPS 2020)</b>, online, 2020. Page: 10247-10258. 
<br><br>
</li>
<li>
Dynamic Regret of Convex and Smooth Functions.[<a href="https://www.lamda.nju.edu.cn/zhaop/publication/NeurIPS&#39;20-Sword.pdf">PDF</a>,  <a href="https://arxiv.org/abs/2007.03479">arXiv</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2020-NeurIPS-Sword.html">bibtex</a>]<br>
Peng Zhao, <u>Yu-Jie Zhang</u>,	Lijun Zhang and Zhi-Hua Zhou. <br> 
In: Advances in Neural Information Processing Systems 33 <b>(NeurIPS 2020)</b>, online, 2020. Page: 12510-12520. 
<br><br>
</li>
<li>
A Simple Online Algorithm for Competing with Dynamic Comparators. [<a href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/uai20.pdf">PDF,</a> <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2020-UAI-simple.html">bibtex,</a> <a href="http://www.lamda.nju.edu.cn/zhangyj/slide/UAI2020_simple.pdf">slide</a>]<br>	
<u>Yu-Jie Zhang</u>, Peng Zhao, and Zhi-Hua Zhou.
<br>
In: Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence <b>(UAI 2020)</b>, online, 2020. 
<br><br>
</li>
</ul>
	  
<div class="section" id="Conference">
<h2>Journal Paper</h2>
<ul>
<li>
Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial Online Convex Optimization. [<a href="http://www.lamda.nju.edu.cn/zhaop/publication/ICML'23_OMD4SEA.pdf">conference version</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/publication/arXiv_OMD4SEA.pdf">Journal version</a>, <a href="http://arxiv.org/abs/2302.04552">arXiv</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2023-ICML-OMD4SEA.html">bibtex</a>]
<br>
Sijia Chen, <u>Yu-Jie Zhang</u>, Wei-Wei Tu, Peng Zhao, and Lijun Zhang.<br>
Journal of Machine Learning Research <b>(JMLR)</b>, to appear, 2024.
<br><br>
</li>	
<li>
Adaptivity and Non-stationarity: Problem-dependent Dynamic Regret for Online Convex Optimization. [<a href = "./Yu-Jie Zhang @ files/paper/Sword++.pdf">PDF</a>, <a href="https://arxiv.org/abs/2112.14368">arXiv</a>, <a href="">bibtex</a>]
<br>
Peng Zhao, <u>Yu-Jie Zhang</u>, Lijun Zhang, and Zhi-Hua Zhou.<br>
Journal of Machine Learning Research <b>(JMLR)</b>, 25(98):1−52, 2024.
<br><br>
</li>		
<li>
Exploratory Machine Learning with Unknown Unknowns. [<a href="https://www.sciencedirect.com/science/article/pii/S0004370223002059">PDF</a>, <a href="http://www.lamda.nju.edu.cn/code_ExML.ashx">code</a>, <a href="./Yu-Jie Zhang @ files/bibtex/ExML_AIJ.html">bibtex</a>] <br> 
Peng Zhao, Jia-Wei Shan, <u>Yu-Jie Zhang</u> and Zhi-Hua Zhou. <br>
Artificial Intelligence <b>(AIJ)</b>, to appear, 2024.
<br><br> 
</li>
</ul>
	  

<h2>Academic Service</h2>
<ul>	
<li style = "margin: 7px 0">Reviewer for Conferences: AAAI (2021, 2024), AISTATS (2021, 2022, 2023, 2024), ECAI (2020), ICLR (2022, 2023, 2024), ICML (2022, 2023, 2024), IJCAI (2020, 2021, 2022, 2023), NeurIPS (2021, 2022, 2023,2024), UAI (2022, 2023, 2024)</li>
<li style = "margin: 7px 0">Reviewer for Journals: JMLR, IEEE TPAMI, FCS</li>
</ul>
	
<h2> Awards & Honors </h2>
<ul>
<li style = "margin: 7px 0">Dean's Award for Outstanding Achievement (Doctoral Course), GSFS, UTokyo, 2025</li>		
<li style = "margin: 7px 0">AISTATS 2025 Best Reviewer, 2025	
<li style = "margin: 7px 0">NeurIPS 2023 Top Reviewer, 2023
<li style = "margin: 7px 0">UAI 2023 Top Reviewer, 2023		
<li style = "margin: 7px 0">NeurIPS 2022 Top Reviewer, 2022
<li style = "margin: 7px 0">Todai Fellowship, 2021</li>	
<li style = "margin: 7px 0">Excellent Graduate of Nanjing University, Nanjing, 2021</li>
<li style = "margin: 7px 0">National Graduate Scholarship for Master Student, MOE of PRC, 2020</li>
<li style = "margin: 7px 0">Excellent Graduate of Tongji University, Shanghai, 2018</li>	
<li style = "margin: 7px 0">Shanghai Undergraduate Scholarship, Shanghai, 2017, 2016</li>
</ul>

<div id="footer">
<div id="footer-text">
Page updated on 2024.06.16.
</div>
</div>
</div>
</div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
