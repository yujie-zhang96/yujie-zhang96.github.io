<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">
<link rel="stylesheet" href="./Yu-Jie Zhang @ files/jemdoc.css" type="text/css">
<title>Yu-Jie Zhang</title>

<style>
  /* 保留顶部横线，这里不再隐藏 #toptitle */

  /* 名字样式调整 */
  .name {
    font-size: 1.6em;
    font-weight: bold;
    display: inline-block;
    margin-bottom: 6px; /* 名字与职位之间的空隙 */
  }

  /* 让照片往下移一点 */
  .photo-cell {
    padding-top: 12px; /* 调整这个值可控制下移距离 */
  }
</style>
</head>

<body>
<div id="layout-content">

  <div id="toptitle"></div> <!-- 顶部横线保留 -->

  <table class="imgtable">
    <tr>
      <td style="padding-left:10px;"></td>
      <td align="left" valign="top">
        <p>
          <span class="name">Yu-Jie Zhang</span><br>
          <span style="font-size:1.08em;">Postdoc Researcher</span><br>
          <span style="font-size:1.08em;">
            <a href="https://www.cs.washington.edu/">Paul G. Allen School of Computer Science &amp; Engineering</a>
          </span><br>
          <span style="font-size:1.08em;">
            <a href="https://www.washington.edu/">University of Washington</a>
          </span><br>
          <span style="font-size:1.08em;"><b>Email:</b> yujiez7 [at] cs.washington.edu</span><br>
        </p>
        [<a href="./resume/twopage/CV_twopage.pdf">CV</a>, 
         <a href="https://scholar.google.com/citations?hl=zh-CN&user=ZDHyUSQAAAAJ">Google Scholar</a>, 
         <a href="https://github.com/yjzzzzz">Github</a>]
      </td>
      <td style="padding-left:130px;"></td>
      <td class="photo-cell" valign="top">
        <a href="./Yu-Jie Zhang @ files/zhangyj_photo1.jpg">
          <img src="./Yu-Jie Zhang @ files/zhangyj_photo1.jpg" alt="Yu-Jie Zhang photo" width="105" height="140">
        </a>
      </td>
    </tr>
  </table>

  <h2>About Me</h2>
  <p>
    I am a postdoctoral researcher in 
    <a href="https://homes.cs.washington.edu/~jamieson/about.html" target="_blank" rel="noopener">
      Prof. Kevin Jamieson’s group
    </a>
    at the University of Washington. Previously, I spent a year as a postdoctoral researcher at the
    <a href="https://www.riken.jp/en/research/labs/aip/imperfect_info_lear/" target="_blank" rel="noopener">
      Imperfect Information Learning Team
    </a>
    at RIKEN AIP. I earned my Ph.D. from 
    <a href="https://www.u-tokyo.ac.jp/en/">the University of Tokyo</a>
    under the supervision of 
    <a href="https://www.ms.k.u-tokyo.ac.jp/sugi/">Prof. Masashi Sugiyama</a>.
    Before that, I completed my M.Sc. with the LAMDA Group at 
    <a href="http://www.nju.edu.cn/" target="_blank">Nanjing University</a>, under the supervision of 
    <a href="https://cs.nju.edu.cn/zhouzh/index.htm">Prof. Zhi-Hua Zhou</a>.
  </p>

  <h2>Research Interests</h2>
  <p>My research interests include Machine Learning and Data Mining. Currently, I am interested in:</p>
  <ul>
    <li>Online Learning and Sequential Decision Making</li>
    <li>Machine Learning in Non-stationary Environments</li>
  </ul>

<div class="section" id="Conference">
<h2>Conference Papers</h2>
<ul>

<li>
Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update. [<a href="https://openreview.net/forum?id=H7vg3IgvHU">PDF</a>, <a href="https://arxiv.org/abs/2507.11847">arXiv</a>, <a href = "https://github.com/yjzzzzz/One-pass_GLB">code</a>,bibtex]
<br>
<u>Yu-Jie Zhang</u>, Sheng-An Xu, Peng Zhao, and Masashi Sugiyama.
<br>
In: Advances in Neural Information Processing Systems 38 <b>(NeurIPS 2025)</b>, San Diego, California, 2025. Page: to appear.
<br><br>
</li>

<li>
Recursive Reward Aggregation. [<a href="https://openreview.net/pdf?id=13lUcKpWy8">PDF</a>, <a href="https://arxiv.org/abs/2507.08537">arXiv</a>, bibtex]
<br>
Yuting Tang, Yivan Zhang, Johannes Ackermann, <u>Yu-Jie Zhang</u>, Soichiro Nishimori, Masashi Sugiyama.
<br>
Reinforcement Learning Conference 2025 <b>(RLC 2025)</b>, Edmonton, Canada.
<br><br>
</li>

<li>
	Non-stationary Online Learning for Curved Losses: Improved Dynamic Regret via Mixability. [<a href="https://openreview.net/pdf?id=TeHF8YjJaw">PDF</a>, <a href="https://www.arxiv.org/pdf/2506.10616">arXiv</a>, bibtex]
	<br>
	<u>Yu-Jie Zhang</u>, Peng Zhao, and Masashi Sugiyama.
	<br>
	In: Proceedings of the 42nd International Conference on Machine Learning <b>(ICML 2025)</b>, Vancouver, Canada, 2025. Page: to appear.
	<br><br>
</li>

<li>
Heavy-Tailed Linear Bandits: Huber Regression with One-Pass Update. [<a href="https://openreview.net/pdf?id=9B5pBbzCwQ">PDF</a>, <a href="https://arxiv.org/abs/2503.00419">arXiv</a>, bibtex]
<br>
Jing Wang, <u>Yu-Jie Zhang</u>, Peng Zhao, and Zhi-Hua Zhou.
<br>
In: Proceedings of the 42nd International Conference on Machine Learning <b>(ICML 2025)</b>, Vancouver, Canada, 2025. Page: to appear.
<br><br>
</li>

<li> 
Provably Efficient Reinforcement Learning with Multinomial Logit Function Approximation. [<a href="https://openreview.net/pdf?id=z2739hYuR3">PDF</a>, <a href="https://arxiv.org/abs/2405.17061">arXiv</a>, <a href="./Yu-Jie Zhang @ files/bibtex/Logistic_MDP.html">bibtex</a>]
<br>
Long-Fei Li, <u>Yu-Jie Zhang</u>, Peng Zhao, and Zhi-Hua Zhou.
<br>
In: Advances in Neural Information Processing Systems 37 <b>(NeurIPS 2024)</b>, Vancouver, Canada, 2024. Page: 58539-58573. 
<br><br>
</li>
<li>
Efficient Non-stationary Online Learning by Wavelets with Applications to Online Distribution Shift Adaptation. [<a href="https://openreview.net/pdf?id=KNedb3bQ4h">PDF</a>, <a href="./Yu-Jie Zhang @ files/bibtex/Efficient_ODS.html">bibtex</a>]
<br>
Yu-Yang Qian, Peng Zhao, <u>Yu-Jie Zhang</u>, Masashi Sugiyama, Zhi-Hua Zhou.
<br>
In: Proceedings of the 41st International Conference on Machine Learning <b>(ICML 2024)</b>, Vienna, Austria, 2024. Page: 41383-41415.
<br><br>
</li>
<li>
Learning with Complementary Labels Revisited: The Selected-Completely-at-Random Setting Is More Practical.  [<a href="https://openreview.net/pdf?id=ykZYLBcA9g">PDF</a>, <a href="./Yu-Jie Zhang @ files/bibtex/NUCL.html">bibtex</a>]
<br>
Wei Wang, Takashi Ishida, <u>Yu-Jie Zhang</u>, Gang Niu, Masashi Sugiyama.
<br>
In: Proceedings of the 41st International Conference on Machine Learning <b>(ICML 2024)</b>, Vienna, Austria. Page: 50683-50710.
<br><br>
</li>	
<li>
Adapting to Continuous Covariate Shift via Online Density Ratio Estimation. [<a href="./Yu-Jie Zhang @ files/paper/CovShift.pdf">PDF</a>, <a href="https://arxiv.org/abs/2302.02552">arXiv</a>, <a href="./Yu-Jie Zhang @ files/bibtex/CovShift.html">bibtex</a>]<br>
<u>Yu-Jie Zhang</u>, Zhen-Yu Zhang, Peng Zhao, and Masashi Sugiyama. <br>
In: Advances in Neural Information Processing Systems 36 <b>(NeurIPS 2023)</b>, New Orleans, Louisiana, 2023. Page: 29074-29113. 	
<br><br>
</li>	
<li>
Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost. [<a href="./Yu-Jie Zhang @ files/paper/MLogB.pdf">PDF</a>, <a href="./Yu-Jie Zhang @ files/bibtex/MLogB.html">bibtex</a>] (Spotlight)<br>
<u>Yu-Jie Zhang</u> and Masashi Sugiyama. <br>
In: Advances in Neural Information Processing Systems 36 <b>(NeurIPS 2023)</b>, New Orleans, Louisiana, 2023. Page: 29741-29782. 	
<br><br>
</li>	
<li>
Imitation Learning from Vague Feedback. [<a href="./Yu-Jie Zhang @ files/paper/VPIL.pdf">PDF</a>, <a href="./Yu-Jie Zhang @ files/bibtex/VPIL.html">bibtex</a>] <br>
Xin-Qiang Cai, <u>Yu-Jie Zhang</u>, Chao-Kai Chiang and Masashi Sugiyama. <br>
In: Advances in Neural Information Processing Systems 36 <b>(NeurIPS 2023)</b>, New Orleans, Louisiana, 2023. Page: 48275-48292. 	
<br><br>
</li>		
<li>
Adapting to Online Label Shift with Provable Guarantees. [<a href="./Yu-Jie Zhang @ files/paper/OLaS.pdf">PDF</a>, <a href="https://arxiv.org/abs/2207.02121">arXiv</a>, <a href = "http://www.lamda.nju.edu.cn/code_ATLAS.ashx" >code</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2022-NeurIPS-OLaS.html">bibtex</a>] 
<br>
Yong Bai*, <u>Yu-Jie Zhang</u>*, Peng Zhao, Masashi Sugiyama, and Zhi-Hua Zhou. (* indicates equal contribution) <br>
In: Advances in Neural Information Processing Systems 35 <b>(NeurIPS 2022)</b>, New Orleans, Louisiana, 2022. Page: 29960-29974.
<br><br>
</li>		
<li>
Adaptive Learning for Weakly Labeled Streams. [<a href="https://www.lamda.nju.edu.cn/zhangzy/KDD'22_AdaStreams.pdf">PDF</a>, <a href="https://www.lamda.nju.edu.cn/code_AdaStreams.ashx">code</a>, <a href="https://www.lamda.nju.edu.cn/zhangzy/bib/2022_KDD_AdaStreams.html">bibtex</a>] <br>
Zhen-Yu Zhang, Yu-Yang Qian, <u>Yu-Jie Zhang</u>, Yuan Jiang, Zhi-Hua Zhou.<br>
In: Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining <b>(KDD 2022)</b>, Washington, DC, 2022. 
<br><br>
</li>	
<li>
Towards Enabling Learnware to Handle Unseen Jobs. [<a href="http://129.211.169.156/publication/aaai21_unseenJob.pdf">PDF</a>,  <a href="http://www.lamda.nju.edu.cn/code_RKME_unseen.ashx">code</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2021-AAAI-UnseenJob.html">bibtex</a>]<br>
<u>Yu-Jie Zhang</u>, Yu-Hu Yan, Peng Zhao and Zhi-Hua Zhou. <br>
In: Proceedings of the 35th AAAI Conference on Artificial Intelligence <b>(AAAI 2021)</b>, online, 2021. Page: 10964-10972.
<br><br>
</li>
<li>
Exploratory Machine Learning with Unknown Unknowns.[<a href="https://www.lamda.nju.edu.cn/zhaop/publication/AAAI&#39;21-ExML.pdf">PDF</a>, <a href="http://www.lamda.nju.edu.cn/code_ExML.ashx">code</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2021-AAAI-ExML.html">bibtex</a>] <br> 
Peng Zhao, <u>Yu-Jie Zhang</u> and Zhi-Hua Zhou. <br>
In: Proceedings of the 35th AAAI Conference on Artificial Intelligence <b>(AAAI 2021)</b>, online, 2021. Page: 10999-11006. 
<br><br> 
</li>
<li>
An Unbiased Risk Estimator for Learning with Augmented Classes.[<a href="https://www.lamda.nju.edu.cn/zhaop/publication/NeurIPS&#39;20-Eulac.pdf">PDF</a>,  <a href="https://arxiv.org/abs/1910.09388">arXiv</a>, <a href="http://www.lamda.nju.edu.cn/code_Eulac.ashx">code</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2020-NeurIPS-Eulac.html">bibtex</a>]<br>
<u>Yu-Jie Zhang</u>, Peng Zhao, Lanjihong Ma and Zhi-Hua Zhou. <br>
 In: Advances in Neural Information Processing Systems 33 <b>(NeurIPS 2020)</b>, online, 2020. Page: 10247-10258. 
<br><br>
</li>
<li>
Dynamic Regret of Convex and Smooth Functions.[<a href="https://www.lamda.nju.edu.cn/zhaop/publication/NeurIPS&#39;20-Sword.pdf">PDF</a>,  <a href="https://arxiv.org/abs/2007.03479">arXiv</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2020-NeurIPS-Sword.html">bibtex</a>]<br>
Peng Zhao, <u>Yu-Jie Zhang</u>,	Lijun Zhang and Zhi-Hua Zhou. <br> 
In: Advances in Neural Information Processing Systems 33 <b>(NeurIPS 2020)</b>, online, 2020. Page: 12510-12520. 
<br><br>
</li>
<li>
A Simple Online Algorithm for Competing with Dynamic Comparators. [<a href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/uai20.pdf">PDF,</a> <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2020-UAI-simple.html">bibtex,</a> <a href="http://www.lamda.nju.edu.cn/zhangyj/slide/UAI2020_simple.pdf">slide</a>]<br>	
<u>Yu-Jie Zhang</u>, Peng Zhao, and Zhi-Hua Zhou.
<br>
In: Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence <b>(UAI 2020)</b>, online, 2020. 
<br><br>
</li>
</ul>
	  
<div class="section" id="Conference">
<h2>Journal Paper</h2>
<ul>
<li>
Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial Online Convex Optimization. [<a href="http://www.lamda.nju.edu.cn/zhaop/publication/ICML'23_OMD4SEA.pdf">conference version</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/publication/arXiv_OMD4SEA.pdf">Journal version</a>, <a href="http://arxiv.org/abs/2302.04552">arXiv</a>, <a href="http://www.lamda.nju.edu.cn/zhaop/bib/2023-ICML-OMD4SEA.html">bibtex</a>]
<br>
Sijia Chen, <u>Yu-Jie Zhang</u>, Wei-Wei Tu, Peng Zhao, and Lijun Zhang.<br>
Journal of Machine Learning Research <b>(JMLR)</b>, to appear, 2024.
<br><br>
</li>	
<li>
Adaptivity and Non-stationarity: Problem-dependent Dynamic Regret for Online Convex Optimization. [<a href = "./Yu-Jie Zhang @ files/paper/Sword++.pdf">PDF</a>, <a href="https://arxiv.org/abs/2112.14368">arXiv</a>, <a href="">bibtex</a>]
<br>
Peng Zhao, <u>Yu-Jie Zhang</u>, Lijun Zhang, and Zhi-Hua Zhou.<br>
Journal of Machine Learning Research <b>(JMLR)</b>, 25(98):1−52, 2024.
<br><br>
</li>		
<li>
Exploratory Machine Learning with Unknown Unknowns. [<a href="https://www.sciencedirect.com/science/article/pii/S0004370223002059">PDF</a>, <a href="http://www.lamda.nju.edu.cn/code_ExML.ashx">code</a>, <a href="./Yu-Jie Zhang @ files/bibtex/ExML_AIJ.html">bibtex</a>] <br> 
Peng Zhao, Jia-Wei Shan, <u>Yu-Jie Zhang</u> and Zhi-Hua Zhou. <br>
Artificial Intelligence <b>(AIJ)</b>, to appear, 2024.
<br><br> 
</li>
</ul>
	  

<h2>Academic Service</h2>
<ul>	
<li style = "margin: 7px 0">Reviewer for Conferences: AAAI (2021, 2024), AISTATS (2021-2024), ECAI (2020), ICLR (2022-2025), ICML (2022-2025), IJCAI (2020-2023), NeurIPS (2021-2025), UAI (2022-2024)</li>
<li style = "margin: 7px 0">Reviewer for Journals: JMLR, IEEE TPAMI, FCS</li>
</ul>
	
<h2> Awards & Honors </h2>
<ul>
<li style = "margin: 7px 0">NeurIPS 2025 Top Reviewer, 2025	
<li style = "margin: 7px 0">Dean's Award for Outstanding Achievement (Doctoral Course), GSFS, UTokyo, 2025</li>		
<li style = "margin: 7px 0">AISTATS 2025 Best Reviewer, 2025	
<li style = "margin: 7px 0">NeurIPS 2023 Top Reviewer, 2023
<li style = "margin: 7px 0">UAI 2023 Top Reviewer, 2023		
<li style = "margin: 7px 0">NeurIPS 2022 Top Reviewer, 2022
<li style = "margin: 7px 0">Todai Fellowship, 2021</li>	
<li style = "margin: 7px 0">Excellent Graduate of Nanjing University, Nanjing, 2021</li>
<li style = "margin: 7px 0">National Graduate Scholarship for Master Student, MOE of PRC, 2020</li>
<li style = "margin: 7px 0">Excellent Graduate of Tongji University, Shanghai, 2018</li>	
<li style = "margin: 7px 0">Shanghai Undergraduate Scholarship, Shanghai, 2017, 2016</li>
</ul>

<div id="footer">
<div id="footer-text">
Page updated on 2025.09.19.
</div>
</div>
</div>
</div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
